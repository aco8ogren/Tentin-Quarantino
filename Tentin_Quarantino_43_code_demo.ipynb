{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Tentin Quarantino \n","## Code Demo\n","This notebook only calls functions that run the actual routines. \n","\n","This takes approximately 1.5 hours running in parallel with 8 cores to train. The evaluation can take up to 5-10 minutes if there are many clusters and the allocation is done with a neural net. We have always run our code on Windows machines. A Requirements.txt in the main directory defines the python environment used to run all our code. "]},{"cell_type":"markdown","metadata":{},"source":["### Import relevant functions"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["\n","import os\n","import sys\n","\n","HomeDIR='Tentin-Quarantino'\n","wd=os.getcwd()\n","DIR=wd[:wd.find(HomeDIR)+len(HomeDIR)]\n","os.chdir(DIR)\n","\n","# %% Imports and path setup\n","\n","# NOTE: Apparently we still need to shield. Can't say I understand why...\n","\n","sys.path.append(os.getcwd())\n","\n","from Dan.EpidModel_parallelized_Counties import SEIIRQD_model\n","from Alex.copy_of_evaluator import evaluate_predictions\n","from Dan.format_sub import format_file_for_evaluation"]},{"cell_type":"markdown","metadata":{},"source":["### Define training parameters"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["#-- Flag to choose whether to train the model\n","    # If this is true, the output file from this run will be used for\n","    # the remainder of the sections\n","isTrainModel = True\n","\n","#-- Define control parameters\n","# Flag to choose whether to save the results or not\n","isSaveRes = True\n","# Filename for saved .npy and .mat files (can include path)\n","    # Make sure the directory structure is present before calling\n","    # NOTE: when clustering, the .mat filename will be used for saving the cluster file\n","sv_flnm_mat = r'Sample_Model_Runs\\Run.mat'\n","sv_flnm_np  = os.path.splitext(sv_flnm_mat)[0] + '.npy'\n","\n","\n","#-- Multiprocessing settings\n","# Flag to choose whether multiprocessing should be used\n","isMultiProc = True\n","# Number of cores to use (logical cores, not physical cores)\n","workers = 2\n","\n","\n","#-- Filtering parameters\n","# Threshold of deaths at and below which a COUNTY will not be trained on\n","    # Filters which COUNTIES are looped over in optimization/minimization loop\n","D_THRES = 97\n","# Last day used for training (good for testing)\n","    # must be a valid pandas.to_datetime() string\n","    # OR: leave as None to train until the latest data for which there is data\n","train_til = '2020-05-10'\n","# Minimum deaths considered in training\n","    # Sets the first DAY which will be calculated as part of the optimization\n","    # by only including days with more than this many deaths. THIS IS DIFFERENT than \n","    # D_THRES. D_THRES selects which counties are trained on and train_Dfrom selects \n","    # which DAYS are used for the optimization\n","train_Dfrom = 7\n","# Minimum number of days required for a county to be trained on\n","    # After filtering using train_Dfrom and D_THRES, this makes sure that there\n","    # are at least min_train_days worth of days to train the model on (for fit_leastsqz)\n","min_train_days = 5\n","\n","\n","#-- Clustering settings\n","# Enable clustering: combines the low-death counties into clusters for training\n","    # When False, the code will run as it used to\n","isCluster = True\n","\n","cluster_max_radius = 0\n","\n","\n","#-- Sub-select counties to train on\n","# Flag to choose whether to sub-select\n","isSubSelect = False\n","# List of counties which should be considered\n","    # NOTE: This just removes ALL other counties from the df as soon as it can\n","just_train_these_fips = [36061, 6037]\n","    \n","\n","#-- Method used for choosing initial conditions\n","    # True: Use the same vector (hardcoded) as the initial conditions for all counties\n","    # False: Calculate unique initial conditions for each county \n","isConstInitCond = True\n","# When calculating unique conditions for each county, define fudge factors:\n","init_vec = (4.901,          # T : Is = T*cases      Old: 3.933\n","            0.020,          # R : Ia = R*Itot       Old: 0.862\n","            0.114)          # F : E  = F*Is         Old: 3.014\n","\n","\n","#-- When not multiprocessing, enable bokeh plotting (since won't cause issue)\n","# Flag to stating whether to plot. This only matters when not multiprocessing (isMultiProc=False)\n","    # When isMultiProc=True, bokeh will cause errors so we ignore this flag\n","isPlotBokeh     = False\n","\n","\n","#-- Set verbosity for printing\n","#-- Verbosity explanation:\n","# There are multiple levels of verbosity based on the provided integer\n","#   0 :     No print statements are executed\n","#   1 :     Only total time is printed\n","#   2 :     Only prints in main function are shown (those in par_fun are suppressed)\n","#   3 :     (DEFAULT) All print statements are executed\n","# *** Error-related prints are always printed\n","verbosity = 3\n","\n","#-- Set hyperparameters\n","# p_err_frac = 0.0995764604328379   # The size of the uncertainty that we have on our optimal SEIIRQD parameters. This affects the size of our quantile differences.\n","p_err_frac = 0.097   # The size of the uncertainty that we have on our optimal SEIIRQD parameters. This affects the size of our quantile differences.\n","death_weight = 5   # The weight with which we multiply the death error in SEIIRQD optimization. The death data is trusted death_weight times more than the symptomatic infected data.\n","alpha = 0.00341564933361549         # alpha of the LeakyReLU for modifying the symptomatic infected error. i.e. if alpha = 0 ==> no penalty for overestimating Sympt Inf. alpha = 1 ==> as much penalty for overestimating as underestimating.\n"]},{"cell_type":"markdown","metadata":{},"source":["### Define Formattin Parameters"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["#-- Flag to choose whether to format a model's .mat output file\n","isFormat = True\n","\n","#-- Define control parameters\n","# Flag to distribue cluster deaths amongst counties naively\n","isAllocCounties = False\n","# Allocating using the mean number of num_alloc_days days BEFORE alloc_day\n","num_alloc_days=5\n","alloc_day=train_til\n","# Flag to translate cummulative data to daily counts\n","isComputeDaily = True\n","\n","\n","\n","#-- Options for allocation using Neural Net\n","# Flag to distribute deaths with neural net\n","isAllocNN=True\n","# Number of days of death inputs\n","numDeaths=2\n","# Number of days of cases inputs\n","numCases=2\n","# Number of days of mobility inputs\n","numMobility=2\n","# Number of days of deaths outputs to average over\n","lenOutput=5\n","# Flag to remove data points with zero deaths for inputs and output\n","remove_sparse=True\n","# Number of epochs with no decrease in validation loss before training stops\n","Patience=4\n","# Dropout rate for dropout layers between the two hidden dense layers\n","DropoutRate=0.15\n","# Flag to retrain neural net or just look for model in directory\n","retrain=True\n","# Directory to save or load model from\n","modelDir=r'Sample_Model_Runs\\NN_Model'\n","\n","\n","#-- When a model was not trained, provide filename to format\n","    # if a model was trained, that filename will automatically be used\n","format_flnm_in = r'Sample_Model_Runs\\Run.mat'\n","\n","#-- Provide filename for output file \n","format_flnm_out = os.path.splitext(format_flnm_in)[0] + '.csv'"]},{"cell_type":"markdown","metadata":{},"source":["### Define Evaluation Parameters"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["\n","#-- Flag to choose whether to evaluate a .csv file\n","isEval = True\n","\n","\n","#-- When model was not formatted, provide a filename to evaluate\n","    # if a model was formatted, that filename will automatically be used\n","eval_flnm_in = r'Sample_Model_Runs\\Run.csv'\n","\n","#-- Day from which we should evaluate \n","    # in format 'YYYY-MM-DD'\n","eval_start_day = '2020-04-21'\n","\n","#-- Day until which we should evaluate\n","    # in format 'YYYY-MM-DD'\n","    # Set to None to evaluate until most recent day of data\n","eval_end_day = '2020-05-23'\n","# eval_end_day = None\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### Set correct file paths"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["\n","#-- If the user says to train a model but doesn't save the result, we can't\n","    # run the remaining sections since we won't have the results to format/eval\n","if isTrainModel and (not isSaveRes):\n","    if isFormat:\n","        raise ValueError(\"isTrainModel=True but isSaveRes=false so we can't format the file.\")\n","    if isEval:\n","        raise ValueError(\"isTrainModel=True but isSaveRes=false so we can't evaluate the file.\")\n","\n","#-- If the user trains a model, use the output to format\n","if isFormat and isTrainModel:\n","    format_flnm_in = sv_flnm_mat\n","    format_flnm_out = os.path.splitext(format_flnm_in)[0] + '.csv'\n","\n","# If the user formats a model, use the output to evaluate\n","if isEval and isFormat:\n","    eval_flnm_in = format_flnm_out\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### Define full run function"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# Needed as a function for the optional hyperparameter optimization \n","if __name__ == '__main__':\n","    def runFull(init_vec):\n","        if isTrainModel:\n","            print('\\n\\n------ Training Model ------')\n","            SEIIRQD_model(HYPERPARAMS = (p_err_frac,D_THRES,death_weight,alpha),\n","                            isSaveRes = isSaveRes,\n","                            sv_flnm_np=sv_flnm_np,\n","                            sv_flnm_mat = sv_flnm_mat,\n","                            isMultiProc = isMultiProc,\n","                            workers = workers,\n","                            train_til = train_til,\n","                            train_Dfrom = train_Dfrom,\n","                            min_train_days = min_train_days,\n","                            isSubSelect = isSubSelect,\n","                            just_train_these_fips = just_train_these_fips,\n","                            isPlotBokeh = isPlotBokeh, \n","                            isConstInitCond = isConstInitCond,\n","                            init_vec = init_vec,\n","                            verbosity = verbosity,\n","                            isCluster = isCluster, cluster_max_radius = cluster_max_radius)\n","            if isSaveRes:\n","                print('*** Model results saved to:\\n    %s\\n    %s'%(sv_flnm_mat, sv_flnm_np))\n","                \n","\n","\n","        if isFormat:\n","            print('\\n------ Formatting File ------')\n","            print('*** Input filename:\\n    %s'%format_flnm_in)\n","\n","            format_file_for_evaluation( format_flnm_in,\n","                                        format_flnm_out,\n","                                        isAllocCounties = isAllocCounties,\n","                                        isComputeDaily = isComputeDaily,\n","                                        alloc_day=alloc_day,\n","                                        num_alloc_days=num_alloc_days,\n","                                        isAllocNN=isAllocNN,\n","                                        retrain=retrain,\n","                                        numDeaths=numDeaths,\n","                                        numCases=numCases,\n","                                        numMobility=numMobility,\n","                                        lenOutput=lenOutput,\n","                                        remove_sparse=remove_sparse,\n","                                        Patience=Patience,\n","                                        DropoutRate=DropoutRate,\n","                                        modelDir=modelDir)\n","\n","            \n","            print('*** Formatted file:\\n    %s'%format_flnm_out)\n","            \n","\n","        if isEval:\n","            print('\\n------ Evaluating File ------')\n","\n","            \n","            print('*** Input filename:\\n    %s'%eval_flnm_in)\n","            print('\\n\\n')\n","            \n","            score = evaluate_predictions(eval_flnm_in,\n","                                            eval_start_day,\n","                                            end_date = eval_end_day)\n","            return score"]},{"cell_type":"markdown","metadata":{},"source":["### Run runFull funtion to train, format, and/or evaluate the model. "]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":"\n------ Formatting File ------\n*** Input filename:\n    Josh\\PracticeOutputs\\Baseline_with_clusters.npy\n2\nc:\\Users\\lassm\\NotDocuments\\CS156b\\number2\\Tentin-Quarantino\\seirqEnv\\lib\\site-packages\\pandas\\core\\frame.py:4153: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  downcast=downcast,\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n101\n102\n103\n104\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n118\n119\n120\n121\n122\n123\n124\n125\n126\n127\n128\n129\n130\n131\n132\n133\n134\n135\n136\n137\n138\n139\n140\n141\n142\n143\n144\n145\n146\n147\n148\n149\n150\n151\n152\n153\n154\n155\n156\n157\n158\n159\n160\n161\nEpoch 1/200\n1383/1383 [==============================] - 2s 2ms/step - loss: 0.0956 - val_loss: 0.0190\nEpoch 2/200\n1383/1383 [==============================] - 2s 2ms/step - loss: 0.0232 - val_loss: 0.0193\nEpoch 3/200\n1383/1383 [==============================] - 2s 1ms/step - loss: 0.0168 - val_loss: 0.0187\nEpoch 4/200\n1383/1383 [==============================] - 3s 2ms/step - loss: 0.0144 - val_loss: 0.0179\nEpoch 5/200\n1383/1383 [==============================] - 2s 2ms/step - loss: 0.0140 - val_loss: 0.0172\nEpoch 6/200\n1383/1383 [==============================] - 2s 2ms/step - loss: 0.0133 - val_loss: 0.0170\nEpoch 7/200\n1383/1383 [==============================] - 2s 2ms/step - loss: 0.0133 - val_loss: 0.0166\nEpoch 8/200\n1383/1383 [==============================] - 2s 2ms/step - loss: 0.0127 - val_loss: 0.0163\nEpoch 9/200\n1383/1383 [==============================] - 2s 2ms/step - loss: 0.0125 - val_loss: 0.0162\nEpoch 10/200\n1383/1383 [==============================] - 2s 2ms/step - loss: 0.0123 - val_loss: 0.0161\nEpoch 11/200\n1383/1383 [==============================] - 3s 2ms/step - loss: 0.0124 - val_loss: 0.0161\nEpoch 12/200\n1383/1383 [==============================] - 2s 2ms/step - loss: 0.0122 - val_loss: 0.0163\nEpoch 13/200\n1383/1383 [==============================] - 2s 2ms/step - loss: 0.0121 - val_loss: 0.0161\nEpoch 14/200\n1383/1383 [==============================] - 2s 2ms/step - loss: 0.0122 - val_loss: 0.0163\nEpoch 15/200\n1383/1383 [==============================] - 2s 2ms/step - loss: 0.0121 - val_loss: 0.0160\nEpoch 16/200\n1383/1383 [==============================] - 2s 2ms/step - loss: 0.0121 - val_loss: 0.0160\nEpoch 17/200\n1383/1383 [==============================] - 3s 2ms/step - loss: 0.0121 - val_loss: 0.0161\nEpoch 18/200\n1383/1383 [==============================] - 3s 2ms/step - loss: 0.0120 - val_loss: 0.0161\nEpoch 19/200\n1383/1383 [==============================] - 3s 2ms/step - loss: 0.0119 - val_loss: 0.0161\n*** Formatted file:\n    Josh\\PracticeOutputs\\Baseline_with_clusters.csv\n\n------ Evaluating File ------\n*** Input filename:\n    Josh\\PracticeOutputs\\Baseline_with_clusters.csv\n\n\n\nEvaluating until: 2020-05-23\nGot score of 0.162791\n"}],"source":["if __name__ == '__main__':\n","    runFull(init_vec)"]}],"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7-final"},"orig_nbformat":2,"kernelspec":{"name":"python37764bitseirqenvvenvcb871cc5ebc64324b78d9b5ecab67f46","display_name":"Python 3.7.7 64-bit ('seirqEnv': venv)"}},"nbformat":4,"nbformat_minor":2}