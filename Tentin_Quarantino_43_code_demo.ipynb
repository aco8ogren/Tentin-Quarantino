{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Tentin Quarantino \n","## Code Demo\n","This notebook only calls functions that run the actual routines. "]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["\n","import os\n","import sys\n","\n","HomeDIR='Tentin-Quarantino'\n","wd=os.getcwd()\n","DIR=wd[:wd.find(HomeDIR)+len(HomeDIR)]\n","os.chdir(DIR)\n","\n","# %% Imports and path setup\n","\n","# NOTE: Apparently we still need to shield. Can't say I understand why...\n","\n","sys.path.append(os.getcwd())\n","\n","from Dan.EpidModel_parallelized_Counties import SEIIRQD_model\n","from Alex.copy_of_evaluator import evaluate_predictions\n","from Dan.format_sub import format_file_for_evaluation"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["#-- Flag to choose whether to train the model\n","    # If this is true, the output file from this run will be used for\n","    # the remainder of the sections\n","isTrainModel = True\n","\n","#-- Define control parameters\n","# Flag to choose whether to save the results or not\n","isSaveRes = True\n","# Filename for saved .npy and .mat files (can include path)\n","    # Make sure the directory structure is present before calling\n","    # NOTE: when clustering, the .mat filename will be used for saving the cluster file\n","sv_flnm_mat = r'Josh\\PracticeOutputs\\Ipy.mat'\n","sv_flnm_np  = os.path.splitext(sv_flnm_mat)[0] + '.npy'\n","\n","\n","#-- Multiprocessing settings\n","# Flag to choose whether multiprocessing should be used\n","isMultiProc = True\n","# Number of cores to use (logical cores, not physical cores)\n","workers = 2\n","\n","\n","#-- Filtering parameters\n","# Threshold of deaths at and below which a COUNTY will not be trained on\n","    # Filters which COUNTIES are looped over in optimization/minimization loop\n","D_THRES = 97\n","# Last day used for training (good for testing)\n","    # must be a valid pandas.to_datetime() string\n","    # OR: leave as None to train until the latest data for which there is data\n","train_til = '2020-05-10'\n","# Minimum deaths considered in training\n","    # Sets the first DAY which will be calculated as part of the optimization\n","    # by only including days with more than this many deaths. THIS IS DIFFERENT than \n","    # D_THRES. D_THRES selects which counties are trained on and train_Dfrom selects \n","    # which DAYS are used for the optimization\n","train_Dfrom = 7\n","# Minimum number of days required for a county to be trained on\n","    # After filtering using train_Dfrom and D_THRES, this makes sure that there\n","    # are at least min_train_days worth of days to train the model on (for fit_leastsqz)\n","min_train_days = 5\n","\n","\n","#-- Clustering settings\n","# Enable clustering: combines the low-death counties into clusters for training\n","    # When False, the code will run as it used to\n","isCluster = True\n","\n","cluster_max_radius = 0\n","\n","\n","#-- Sub-select counties to train on\n","# Flag to choose whether to sub-select\n","isSubSelect = True\n","# List of counties which should be considered\n","    # NOTE: This just removes ALL other counties from the df as soon as it can\n","just_train_these_fips = [36061, 6037]\n","    # 21131, 21051, 21193, 21119, 21109, 21189, 21025, 21071, 21115,\n","    # 21197, 21175, 21165, 21049, 21173, 21127, 21011, 21205, 21043,\n","    # 21181, 21069, 21019, 39087, 21089, 21135, 21161, 21023, 39145,\n","    # 39001, 39015, 39079, 39131, 39025, 39071, 39141, 39027, 39047,\n","    # 39129, 39057, 39113, 39045, 39097, 39023, 39109]\n","    #35006, 35043, 35031]\n","    # GOOD 6037,17031, TROUBLE 53061,36059,53033  NOT SURE 36087\n","#[36061, 36059, 26163, 17031, 36103, 36119, 34013, 34003, 6037,  9001,  34017, 26125, 25017, 34039, 26099, 9003] \n","\n","\n","#-- Method used for choosing initial conditions\n","    # True: Use the same vector (hardcoded) as the initial conditions for all counties\n","    # False: Calculate unique initial conditions for each county \n","isConstInitCond = True\n","# When calculating unique conditions for each county, define fudge factors:\n","init_vec = (4.901,          # T : Is = T*cases      Old: 3.933\n","            0.020,          # R : Ia = R*Itot       Old: 0.862\n","            0.114)          # F : E  = F*Is         Old: 3.014\n","\n","\n","#-- When not multiprocessing, enable bokeh plotting (since won't cause issue)\n","# Flag to stating whether to plot. This only matters when not multiprocessing (isMultiProc=False)\n","    # When isMultiProc=True, bokeh will cause errors so we ignore this flag\n","isPlotBokeh     = False\n","\n","\n","#-- Set verbosity for printing\n","#-- Verbosity explanation:\n","# There are multiple levels of verbosity based on the provided integer\n","#   0 :     No print statements are executed\n","#   1 :     Only total time is printed\n","#   2 :     Only prints in main function are shown (those in par_fun are suppressed)\n","#   3 :     (DEFAULT) All print statements are executed\n","# *** Error-related prints are always printed\n","verbosity = 3\n","\n","#-- Set hyperparameters\n","# p_err_frac = 0.0995764604328379   # The size of the uncertainty that we have on our optimal SEIIRQD parameters. This affects the size of our quantile differences.\n","p_err_frac = 0.097   # The size of the uncertainty that we have on our optimal SEIIRQD parameters. This affects the size of our quantile differences.\n","death_weight = 5   # The weight with which we multiply the death error in SEIIRQD optimization. The death data is trusted death_weight times more than the symptomatic infected data.\n","alpha = 0.00341564933361549         # alpha of the LeakyReLU for modifying the symptomatic infected error. i.e. if alpha = 0 ==> no penalty for overestimating Sympt Inf. alpha = 1 ==> as much penalty for overestimating as underestimating.\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["\n","#-- Flag to choose whether to format a model's .mat output file\n","isFormat = True\n","\n","#-- Define control parameters\n","# Flag to distribue state deaths amongst counties\n","isAllocCounties = False\n","# Allocating using the mean number of num_alloc_days days BEFORE alloc_day\n","num_alloc_days=5\n","alloc_day=train_til\n","# Flag to translate cummulative data to daily counts\n","isComputeDaily = True\n","\n","\n","\n","#-- Options for allocation using Neural Net\n","# Flag to distribute deaths with neural net\n","isAllocNN=True\n","# Number of days of death inputs\n","numDeaths=2\n","# Number of days of cases inputs\n","numCases=2\n","# Number of days of mobility inputs\n","numMobility=2\n","# Number of days of deaths outputs to average over\n","lenOutput=5\n","# Flag to remove data points with zero deaths for inputs and output\n","remove_sparse=True\n","# Number of epochs with no decrease in validation loss before training stops\n","Patience=4\n","# Dropout rate for dropout layers between the two hidden dense layers\n","DropoutRate=0.15\n","# Flag to retrain neural net or just look for model in directory\n","retrain=True\n","# Directory to save or load model from\n","modelDir=r'Josh\\Alloc_NN\\DansStuff'\n","\n","\n","#-- When a model was not trained, provide filename to format\n","    # if a model was trained, that filename will automatically be used\n","format_flnm_in = r'Josh\\PracticeOutputs\\Final Submission\\FinalSubmission_Checkout70d1ee_TrainTil04_1MonthInterval.npy'\n","\n","#-- Provide filename for output file \n","format_flnm_out = os.path.splitext(format_flnm_in)[0] + '.csv'\n","\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["\n","#-- Flag to choose whether to evaluate a .csv file\n","isEval = True\n","\n","\n","#-- When model was not formatted, provide a filename to evaluate\n","    # if a model was formatted, that filename will automatically be used\n","eval_flnm_in = r'Josh\\PracticeOutputs\\Final Submission\\FinalSubmission_Checkout70d1ee_TrainTil0420_1MonthInterval.csv'\n","\n","#-- Day from which we should evaluate \n","    # in format 'YYYY-MM-DD'\n","eval_start_day = '2020-04-21'\n","\n","#-- Day until which we should evaluate\n","    # in format 'YYYY-MM-DD'\n","    # Set to None to evaluate until most recent day of data\n","eval_end_day = '2020-05-23'\n","# eval_end_day = None\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["\n","#-- If the user says to train a model but doesn't save the result, we can't\n","    # run the remaining sections since we won't have the results to format/eval\n","if isTrainModel and (not isSaveRes):\n","    if isFormat:\n","        raise ValueError(\"isTrainModel=True but isSaveRes=false so we can't format the file.\")\n","    if isEval:\n","        raise ValueError(\"isTrainModel=True but isSaveRes=false so we can't evaluate the file.\")\n","\n","#-- If the user trains a model, use the output to format\n","if isFormat and isTrainModel:\n","    format_flnm_in = sv_flnm_mat\n","    format_flnm_out = os.path.splitext(format_flnm_in)[0] + '.csv'\n","\n","# If the user formats a model, use the output to evaluate\n","if isEval and isFormat:\n","    eval_flnm_in = format_flnm_out\n","\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Needed as a function for the optional hyperparameter optimization \n","if __name__ == '__main__':\n","    def runFull(init_vec):\n","        if isTrainModel:\n","            print('\\n\\n------ Training Model ------')\n","            SEIIRQD_model(HYPERPARAMS = (p_err_frac,D_THRES,death_weight,alpha),\n","                            isSaveRes = isSaveRes,\n","                            sv_flnm_np=sv_flnm_np,\n","                            sv_flnm_mat = sv_flnm_mat,\n","                            isMultiProc = isMultiProc,\n","                            workers = workers,\n","                            train_til = train_til,\n","                            train_Dfrom = train_Dfrom,\n","                            min_train_days = min_train_days,\n","                            isSubSelect = isSubSelect,\n","                            just_train_these_fips = just_train_these_fips,\n","                            isPlotBokeh = isPlotBokeh, \n","                            isConstInitCond = isConstInitCond,\n","                            init_vec = init_vec,\n","                            verbosity = verbosity,\n","                            isCluster = isCluster, cluster_max_radius = cluster_max_radius)\n","            if isSaveRes:\n","                print('*** Model results saved to:\\n    %s\\n    %s'%(sv_flnm_mat, sv_flnm_np))\n","                \n","\n","\n","        if isFormat:\n","            print('\\n------ Formatting File ------')\n","\n","            if not isRunInitConHyper:\n","                print('*** Input filename:\\n    %s'%format_flnm_in)\n","\n","            format_file_for_evaluation( format_flnm_in,\n","                                        format_flnm_out,\n","                                        isAllocCounties = isAllocCounties,\n","                                        isComputeDaily = isComputeDaily,\n","                                        alloc_day=alloc_day,\n","                                        num_alloc_days=num_alloc_days,\n","                                        isAllocNN=isAllocNN,\n","                                        retrain=retrain,\n","                                        numDeaths=numDeaths,\n","                                        numCases=numCases,\n","                                        numMobility=numMobility,\n","                                        lenOutput=lenOutput,\n","                                        remove_sparse=remove_sparse,\n","                                        Patience=Patience,\n","                                        DropoutRate=DropoutRate,\n","                                        modelDir=modelDir)\n","\n","            if not isRunInitConHyper:\n","                print('*** Formatted file:\\n    %s'%format_flnm_out)\n","            \n","\n","        if isEval:\n","            print('\\n------ Evaluating File ------')\n","\n","            if not isRunInitConHyper:\n","                print('*** Input filename:\\n    %s'%eval_flnm_in)\n","                print('\\n\\n')\n","            \n","            score = evaluate_predictions(eval_flnm_in,\n","                                            eval_start_day,\n","                                            end_date = eval_end_day)\n","            return score"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":"'__main__'"},"metadata":{},"execution_count":12}],"source":["if __name__ == '__main__':\n","    runFull(init_vec)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7-final"},"orig_nbformat":2,"kernelspec":{"name":"python37764bitseirqenvvenvcb871cc5ebc64324b78d9b5ecab67f46","display_name":"Python 3.7.7 64-bit ('seirqEnv': venv)"}},"nbformat":4,"nbformat_minor":2}